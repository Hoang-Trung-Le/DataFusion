{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from scripts.DSI.DS import DempsterShafer\n",
    "from scripts.DSI.DSI_input import DempsterShaferInputHandler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the deep learning models\n",
    "# models = ['1D CNN', 'LSTM', 'BiLSTM', 'CNN-LSTM', 'GRU', 'ANN']\n",
    "\n",
    "# # Generate random values for the 'r' column\n",
    "# r_values = np.random.uniform(-1, 1, len(models))\n",
    "\n",
    "# # Create the dataframe\n",
    "# df = pd.DataFrame({'rmse': np.random.uniform(0, 5, len(models)), 'r': r_values}, index=models)\n",
    "# df.index.name = 'Model'\n",
    "\n",
    "# # Print the dataframe\n",
    "# print(df)\n",
    "# df.to_csv(\"../../data/nowcast_dsi.csv\", index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Pearson_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1D CNN</th>\n",
       "      <td>4.041753</td>\n",
       "      <td>0.015509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>4.372815</td>\n",
       "      <td>-0.276929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiLSTM</th>\n",
       "      <td>4.450400</td>\n",
       "      <td>-0.641712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN-LSTM</th>\n",
       "      <td>1.982408</td>\n",
       "      <td>0.858672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>4.186350</td>\n",
       "      <td>0.112732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANN</th>\n",
       "      <td>3.640281</td>\n",
       "      <td>0.231497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              RMSE  Pearson_r\n",
       "Model                        \n",
       "1D CNN    4.041753   0.015509\n",
       "LSTM      4.372815  -0.276929\n",
       "BiLSTM    4.450400  -0.641712\n",
       "CNN-LSTM  1.982408   0.858672\n",
       "GRU       4.186350   0.112732\n",
       "ANN       3.640281   0.231497"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nowcast_multimodel_data = pd.read_csv(\"../../data/nowcast_dsi.csv\", index_col=\"Model\")\n",
    "parameters = [\"RMSE\", \"Pearson_r\"]\n",
    "nowcast_multimodel_data.columns = parameters\n",
    "nowcast_multimodel_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(y_true, y_pred):\n",
    "    stats = {}\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # mae = mean_absolute_error(y_true, y_pred)\n",
    "    pearson_r, _ = pearsonr(y_true, y_pred)\n",
    "    # r2 = r2_score(y_true, y_pred)\n",
    "    # max_error_value = max_error(y_true, y_pred)\n",
    "    # mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    # return rmse, mae, pearson_r, r2, max_error_value, mape\n",
    "    stats[\"RMSE\"] = rmse\n",
    "    stats[\"Pearson_r\"] = pearson_r\n",
    "    return stats\n",
    "\n",
    "\n",
    "def evaluate_forecast_models(forecast_dict, observation_df):\n",
    "    \"\"\"\n",
    "    Evaluate multiple forecast models against actual observations.\n",
    "\n",
    "    Args:\n",
    "    - forecast_dict: Dictionary of forecasted values with the format:\n",
    "        {\"forecast_hour\": {\"model1\": forecast_df1, \"model2\": forecast_df2, ...}}\n",
    "    - observation_df: DataFrame with the actual observed values, indexed by time.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the calculated statistics for each model.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    forecast_length = len(observation_df)\n",
    "    for forecast_hour, models in forecast_dict.items():\n",
    "        model_stats = {}\n",
    "        model_stats_df = pd.DataFrame()\n",
    "        for model_name, forecast_df in models.items():\n",
    "            if len(forecast_df) < len(observation_df):\n",
    "                raise ValueError(\"Forecast and observation lengths do not match.\")\n",
    "            # Align forecast and observation data based on DateTimeIndex\n",
    "            common_index = forecast_df.index.intersection(observation_df.index)\n",
    "\n",
    "            # Ensure forecast values cover the desired observation period\n",
    "            relevant_forecast = forecast_df.loc[common_index[:forecast_length]]\n",
    "            relevant_observation = observation_df.loc[common_index[:forecast_length]]\n",
    "\n",
    "            # Calculate statistics only if there are enough data points\n",
    "            if len(relevant_observation) == forecast_length:\n",
    "                stats = calculate_statistics(\n",
    "                    relevant_forecast.values.flatten(),\n",
    "                    relevant_observation.values.flatten(),\n",
    "                )\n",
    "                model_stats[model_name] = stats\n",
    "                if model_stats.empty:\n",
    "                    model_stats = pd.DataFrame.from_dict(model_stats, orient=\"index\")\n",
    "                else:\n",
    "                    model_stats = pd.concat([model_stats_df, model_stats], axis=1)\n",
    "\n",
    "        results[forecast_hour] = model_stats\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# forecasts = {\"6\": {\"LSTM\": lstm_forecast, \"CNN\": cnn_forecast}, \"12\": {\"LSTM\": lstm_forecast_12, \"CNN\": cnn_forecast_12}}\n",
    "# observations = actual_observations\n",
    "# stats = calculate_statistics(forecasts, observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'6': {'Model_1': {'RMSE': 46.06055056865524, 'Pearson_r': -0.1500307744453881}, 'Model_2': {'RMSE': 45.61961229922331, 'Pearson_r': -0.030381329066097928}, 'Model_3': {'RMSE': 47.59428055705401, 'Pearson_r': -0.2779249015068874}}, '12': {'Model_1': {'RMSE': 38.219700977593845, 'Pearson_r': 0.12163626774227945}, 'Model_2': {'RMSE': 46.14193596110504, 'Pearson_r': -0.06883608660582284}, 'Model_3': {'RMSE': 48.41753465101365, 'Pearson_r': -0.19993383748272897}}, '24': {'Model_1': {'RMSE': 38.407759765219204, 'Pearson_r': 0.18136988825913675}, 'Model_2': {'RMSE': 44.390708709699915, 'Pearson_r': -0.08173553753997634}, 'Model_3': {'RMSE': 43.91802354570127, 'Pearson_r': 0.21394501245327968}}}\n",
      "\n",
      "Forecast Hour: 6\n",
      "  Model_1 -> RMSE: 46.061, Pearson_r: -0.150\n",
      "  Model_2 -> RMSE: 45.620, Pearson_r: -0.030\n",
      "  Model_3 -> RMSE: 47.594, Pearson_r: -0.278\n",
      "\n",
      "Forecast Hour: 12\n",
      "  Model_1 -> RMSE: 38.220, Pearson_r: 0.122\n",
      "  Model_2 -> RMSE: 46.142, Pearson_r: -0.069\n",
      "  Model_3 -> RMSE: 48.418, Pearson_r: -0.200\n",
      "\n",
      "Forecast Hour: 24\n",
      "  Model_1 -> RMSE: 38.408, Pearson_r: 0.181\n",
      "  Model_2 -> RMSE: 44.391, Pearson_r: -0.082\n",
      "  Model_3 -> RMSE: 43.918, Pearson_r: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13993807_admin\\AppData\\Local\\Temp\\ipykernel_6252\\573354599.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_index = pd.date_range(start=start_time, periods=periods, freq=freq)\n"
     ]
    }
   ],
   "source": [
    "# # Function to generate dummy forecast and observation data\n",
    "# def generate_dummy_data(start_time, periods, freq, num_models, forecast_length):\n",
    "#     # Create a DateTimeIndex\n",
    "#     time_index = pd.date_range(start=start_time, periods=periods, freq=freq)\n",
    "\n",
    "#     # Generate random data for forecasts\n",
    "#     forecast_dict = {}\n",
    "#     for forecast_hour in [6, 12, 24]:  # Assuming different forecast lengths\n",
    "#         models = {}\n",
    "#         for i in range(1, num_models + 1):\n",
    "#             model_name = f\"Model_{i}\"\n",
    "#             # Generate forecast values with slight variations per model\n",
    "#             forecast_values = np.random.rand(periods) * 100 + i * 5\n",
    "#             models[model_name] = pd.DataFrame(\n",
    "#                 forecast_values, index=time_index, columns=[\"forecast\"]\n",
    "#             )\n",
    "#         forecast_dict[str(forecast_hour)] = models\n",
    "\n",
    "#     # Generate observation data\n",
    "#     observation_values = np.random.rand(periods) * 100\n",
    "#     observation_df = pd.DataFrame(\n",
    "#         observation_values, index=time_index, columns=[\"observed\"]\n",
    "#     )\n",
    "\n",
    "#     return forecast_dict, observation_df\n",
    "\n",
    "\n",
    "# # Parameters\n",
    "# start_time = \"2024-08-01 00:00:00\"\n",
    "# periods = 48  # Total number of hours\n",
    "# freq = \"H\"  # Hourly data\n",
    "# num_models = 3  # Number of models\n",
    "# forecast_length = 6  # Number of hours to evaluate\n",
    "\n",
    "# # Generate dummy data\n",
    "# forecast_dict, observation_df = generate_dummy_data(\n",
    "#     start_time, periods, freq, num_models, forecast_length\n",
    "# )\n",
    "\n",
    "# # Test the evaluate_forecast_models function\n",
    "# evaluation_results = evaluate_forecast_models(forecast_dict, observation_df)\n",
    "\n",
    "# # Print the evaluation results\n",
    "# print(\"Evaluation Results:\", evaluation_results)\n",
    "# for forecast_hour, model_stats in evaluation_results.items():\n",
    "#     print(f\"\\nForecast Hour: {forecast_hour}\")\n",
    "#     for model_name, stats in model_stats.items():\n",
    "#         print(\n",
    "#             f\"  {model_name} -> RMSE: {stats['RMSE']:.3f}, Pearson_r: {stats['Pearson_r']:.3f}\"\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "sampling_matrix = np.array([[0, 1]])\n",
    "print(sampling_matrix.shape)\n",
    "reference_matrix = nowcast_multimodel_data[parameters].values\n",
    "reference_matrix.shape\n",
    "reference_matrix = pd.DataFrame(reference_matrix, columns=parameters)\n",
    "sampling_matrix = pd.DataFrame(sampling_matrix, columns=parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1D CNN', 'LSTM', 'BiLSTM', 'CNN-LSTM', 'GRU', 'ANN']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hypotheses = list(nowcast_multimodel_data.index)\n",
    "test_hypotheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90817742 0.40032692]\n",
      " [0.9825667  0.22219666]\n",
      " [1.         0.        ]\n",
      " [0.44544484 0.91391433]\n",
      " [0.94066825 0.45954704]\n",
      " [0.81796729 0.53188908]]\n",
      "[[0. 1.]]\n",
      "final mass:  [0.0891785  0.07238459 0.06242241 0.64552518 0.09308772 0.03740159]\n",
      "     1D CNN      LSTM    BiLSTM  CNN-LSTM       GRU       ANN\n",
      "0  0.089179  0.072385  0.062422  0.645525  0.093088  0.037402\n"
     ]
    }
   ],
   "source": [
    "# Define the Dempster-Shafer input handler\n",
    "ds_handler = DempsterShaferInputHandler(reference_matrix, sampling_matrix)\n",
    "ds_handler.normalize_data()\n",
    "normalized_reference = ds_handler.get_normalized_reference_matrix()\n",
    "normalized_sampling = ds_handler.get_normalized_sampling_matrix()\n",
    "\n",
    "normalized_reference_np = normalized_reference.to_numpy()\n",
    "normalized_sampling_np = normalized_sampling.to_numpy()\n",
    "print(normalized_reference_np)\n",
    "print(normalized_sampling_np)\n",
    "\n",
    "is_uncertain = \"Uncertain\" in test_hypotheses\n",
    "dsi = DempsterShafer(normalized_reference_np, normalized_sampling_np, is_uncertain)\n",
    "dsi.hypothesis_order(test_hypotheses)\n",
    "a = dsi.result()\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate DSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
